# read-papers
Just for self-motivation

I'm now focusing on `Vision MLP`, `Vision Transformer`, `Transformer`, `Multi-modal`, `Detection`

## Contents
### Classification on ImageNet
Relative Papers: 
- [Vision MLP](https://github.com/rentainhe/what_I_have_read/blob/main/vision_mlp.md)
- [Vision Transformer](https://github.com/rentainhe/what_I_have_read/blob/main/vision_transformer.md)

### Detection
- [One-Stage]()
- [Two-Stage]()

### Multi-Model: VQA2.0, NLVR2...
- [Vision and Language Pretraining](https://github.com/rentainhe/what_I_have_read/blob/main/vision_and_language_pretraining.md)
- [Visual Question Answering]()

### NLP
Prompt Method:
![image](https://user-images.githubusercontent.com/48727989/133720952-38d43a52-bea6-4d6d-85f7-4f8e1c496506.png)
